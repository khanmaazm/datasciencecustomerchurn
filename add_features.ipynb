{"cells":[{"cell_type":"code","source":["from geopy.distance import distance"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb4f50dd-2d02-4133-9c11-0aa84d59afac"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def measure_distance_to_loc(lat, lon, lat_origin = 25.276987, lon_origin = 55.296249):\n  \n  \"\"\"Given a a point defined by its latitude and logitud, returns the distance to a certain origin, by default specified to be Dubai. This function is used to create variables based on the nationality of the customer.\n\n  Parameters:\n  lat: Latitude of the point.\n  lon: Longitude of the point.\n  lat_origin: Latitude of the origin, by default set to Dubai.\n  lon_origin: Longitude of the origin, by default set to Dubai.\n\n  Returns:\n  Distance in kilometers from the speficied point to the origin.\n\n  \"\"\"\n  # by default dubai is the origin\n  if np.isnan(lat + lon):\n      return np.NaN\n  dist_to_loc = distance((lat, lon), (lat_origin, lon_origin)).km\n  return dist_to_loc\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aad15a0e-14c8-45c0-aa66-a16b7d17c6c3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def add_demo_feats(config, mt, resi_detail = None, coords = None):\n  \n  \"\"\"Adds demographic features to master table. The number of rows is always unaltered. Some nationalities from resi detail are changed to match the format from the coords file.\n\n  Parameters:\n  config: configuration dictionary, as defined in get_config.\n  mt: master table to which demographic features are added\n  resi_detail: residential detail data source. If None, it is read from the appropiate file.\n  coords: Dataset specificing the coordinates from each country. If None, it is read from the appropiate file.\n\n  Returns:\n  Data frame with new columns related to demographic features. \n\n  \"\"\"  \n  \n  if resi_detail is None:\n    resi_detail = get_raw_df(config, 'residential_detail')\n  if coords is None:\n    coords = get_raw_df(config, 'coords')\n    \n  coords.loc[:, 'distance_to_dubai'] = coords.apply(lambda x: measure_distance_to_loc(x.latitude, x.longitude, config['model_params']['coords_dubai']['lat'], config['model_params']['coords_dubai']['lon']), axis = 1)\n   \n  # correcting some country names. pd.replace does not work property with the installed pandas version\n  resi_detail.loc[resi_detail.nationality == 'palestine', 'nationality'] = 'lebanon'\n  resi_detail.loc[resi_detail.nationality == 'serbia_and_montenegro', 'nationality'] = 'serbia'\n  resi_detail.loc[resi_detail.nationality == 'philippine', 'nationality'] = 'philippines'\n  resi_detail.loc[resi_detail.nationality == 'ethopia', 'nationality'] = 'ethiopia'\n  resi_detail.loc[resi_detail.nationality == 'korea_south', 'nationality'] = 'south_korea'\n  resi_detail.loc[resi_detail.nationality == 'korea_north', 'nationality'] = 'north_korea'\n  resi_detail.loc[resi_detail.nationality == 'congo_democratic_republic_of_the', 'nationality'] = 'congo_drc'\n  resi_detail.loc[resi_detail.nationality == 'macedonia', 'nationality'] = 'macedonia_fyrom'\n  resi_detail.loc[resi_detail.nationality == 'burma', 'nationality'] = 'myanmar_burma'\n  resi_detail.loc[resi_detail.nationality == 'united_states_of_america', 'nationality'] = 'united_states'\n  resi_detail.loc[resi_detail.nationality == 'emirates', 'nationality'] = 'united_arab_emirates'\n  resi_detail.loc[resi_detail.nationality == 'kyrgistan', 'nationality'] = 'kyrgyzstan'\n  resi_detail.loc[resi_detail.nationality == 'mianmaar', 'nationality'] = 'myanmar_burma'\n  resi_detail.loc[resi_detail.nationality == 'malysia', 'nationality'] = 'malaysia'\n  resi_detail.loc[resi_detail.nationality == 'saudia', 'nationality'] = 'saudi_arabia'\n  resi_detail.loc[resi_detail.nationality == 'trinidad_tobago', 'nationality'] = 'trinidad_and_tobago'\n  resi_detail.loc[resi_detail.nationality == 'ukranain', 'nationality'] = 'ukraine'\n  resi_detail.loc[resi_detail.nationality == 'tunis', 'nationality'] = 'tunisia'  \n  \n  demo_features = pd.merge(resi_detail[['hcode', 'nationality', 'individual_categry']], coords[['name', 'latitude', 'longitude', 'distance_to_dubai']], left_on = 'nationality', right_on = 'name', how = 'left')\n  demo_features.drop(columns = ['nationality', 'name'], inplace = True)\n  new_mt = pd.merge(mt, demo_features, left_on = 'htent', right_on = 'hcode', how = 'left')\n  \n#   assert new_mt.latitude.isna().sum() == 0, 'There are some customers whose country has not been identified'\n  assert new_mt.shape[0] == mt.shape[0], 'The number of rows of the master table with the new demographic features is not correct'\n  \n  new_mt = pd.get_dummies(new_mt, dummy_na=False, columns=['individual_categry'])\n  \n  # replacing nas\n  new_mt.latitude.fillna(24, inplace = True)\n  new_mt.longitude.fillna(69, inplace = True)\n  new_mt.distance_to_dubai.fillna(2500, inplace = True)\n  \n  return new_mt\n  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05e0994f-fa3b-435f-bec0-bf2267bd8624"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def add_unit_feats(config, mt, unit = None, prop = None, unit_type = None):\n  \n  \"\"\"Adds unit features to master table. The number of rows is always unaltered. \n\n  Parameters:\n  config: configuration dictionary, as defined in get_config.\n  mt: master table to which unit features are added.\n  unit: unit data source. If None, it is read from the appropiate file.\n  prop: property data source. If None, it is read from the appropiate file.\n  unit_type: unit type data source. If None, it is read from the appropiate file.\n\n  Returns:\n  Data frame with new columns related to unit features. \n\n  \"\"\"  \n  \n  if unit is None:\n    unit = get_raw_df(config, 'unit')\n  if prop is None:\n    prop = get_raw_df(config, 'property')\n  if unit_type is None:\n    unit_type = get_raw_df(config, 'unit_type')\n    \n  unit_mt = unit[['hproperty', 'hmy', 'hunittype', 'dsqft']]\n  unit_mt.columns = ['hproperty', 'hunit', 'hunittype', 'dsqft']\n  unit_mt = pd.merge(unit_mt, prop, left_on = 'hproperty', right_on = 'hmy', how = 'left').drop(columns = 'hmy')\n  unit_mt = pd.merge(unit_mt, unit_type[['hmy', 'sdesc', 'ibeds', 'ibaths']], left_on = 'hunittype', right_on = 'hmy', how = 'left').drop(columns = 'hmy')\n  \n  unit_mt.sdesc.fillna('unknown', inplace = True)\n  \n  unit_mt['is_luxury_unit'] = ['lux' in str(i) for i in unit_mt.sdesc]\n  unit_mt['is_standard_unit'] = ['sta' in str(i) for i in unit_mt.sdesc]\n  unit_mt['is_economy_unit'] = ['economy' in str(i) for i in unit_mt.sdesc]\n  unit_mt['is_basic_unit'] = ['basic' in str(i) for i in unit_mt.sdesc]\n  unit_mt['is_other_unit'] = (unit_mt[['is_luxury_unit', 'is_standard_unit', 'is_economy_unit', 'is_basic_unit']].sum(axis = 1) == 0)\n  \n  dam_units = ['al_khail_gate', 'shorooq', 'ghoroob', 'remraam', 'layan']\n  other_projects = np.logical_not([x in dam_units for x in unit_mt.saddr2])\n  \n  unit_mt.loc[other_projects, 'saddr2'] = 'other'\n  unit_mt['community'] = unit_mt.saddr2\n  \n  unit_mt = pd.get_dummies(unit_mt, dummy_na=False, columns=['saddr2'])\n  \n  new_mt = pd.merge(mt, unit_mt, on = 'hunit', how = 'left')\n  assert new_mt.shape[0] == mt.shape[0], 'The number of rows of the master table with the new unit features is not correct'\n  \n  # replacing nas\n  new_mt.ibaths.fillna(-1, inplace = True)\n  new_mt.ibeds.fillna(-1, inplace = True)\n  new_mt.dsqft.fillna(1300, inplace = True)\n  \n  for i in dam_units:\n    new_mt['saddr2_' + i].fillna(0, inplace = True)\n  new_mt['saddr2_other'].fillna(True, inplace = True)\n  \n  # formatting data types\n  for i in ['is_luxury_unit', 'is_standard_unit', 'is_economy_unit', 'is_basic_unit', 'is_other_unit']:\n    new_mt[i] = new_mt[i].fillna(0).astype(bool)\n    \n  new_mt['ibaths'] = new_mt['ibaths'].astype(int, errors = 'ignore')\n  new_mt['ibeds'] = new_mt['ibeds'].astype(int, errors = 'ignore')\n  \n  return new_mt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"630970d6-c15d-460c-b809-60a4f5507374"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def add_avg_price_feat(config, mt):\n  \n  \"\"\"Adds price ratio features to master table. The number of rows is always unaltered. \n  \n  The features added are:\n  - Ratio between rent and average rent for units scored in that month.\n  - Ratio between price per square feet and average price per square feet in that month.\n  \n  The averages are computed globally, at community level and at type level (e.g., luxury units)\n\n  Parameters:\n  config: configuration dictionary, as defined in get_config.\n  mt: master table to which unit features are added\n\n  Returns:\n  Data frame with new columns related to price ratios features. \n\n  \"\"\"  \n  \n  # global average price\n  monthly_price = mt.groupby('id_date')['crent', 'price_per_sq_ft'].mean().reset_index()\n  monthly_price.columns = ['id_date', 'avg_monthly_price', 'avg_price_per_sq_ft']\n  \n  new_mt = mt.copy()\n  new_mt = pd.merge(new_mt, monthly_price, on = 'id_date', how = 'left')\n  \n  new_mt['ratio_price_avg'] = new_mt['crent'] /  new_mt['avg_monthly_price']\n  new_mt['ratio_price_sqft_avg'] = new_mt['price_per_sq_ft'] /  new_mt['avg_price_per_sq_ft']\n  \n  assert new_mt.shape[0] == mt.shape[0], 'The number of rows of the master table with the new ratio of the price and the monthly average price is wrong'\n  \n  new_mt.drop(columns = 'avg_monthly_price', inplace = True)\n  \n  # average prices per community\n  monthly_price_comm = mt.groupby(['id_date', 'community'])['crent', 'price_per_sq_ft'].mean().reset_index()\n  monthly_price_comm.columns = ['id_date', 'community', 'avg_monthly_price_comm', 'avg_price_per_sq_ft_comm']\n  \n  new_mt = pd.merge(new_mt, monthly_price_comm, on = ['id_date', 'community'], how = 'left')\n  \n  assert new_mt.shape[0] == mt.shape[0], 'The number of rows of the master table with the new ratio of the price and the monthly average price per community is wrong'\n  new_mt['ratio_price_avg_comm'] = new_mt['crent'] /  new_mt['avg_monthly_price_comm']\n  new_mt['ratio_price_sqft_avg_comm'] = new_mt['price_per_sq_ft'] /  new_mt['avg_price_per_sq_ft_comm']\n  \n  \n  # average prices per unit type  \n  is_unit_cols = [x for x in new_mt.columns if x.startswith('is_') and x.endswith('_unit')]\n  aux_vct = np.zeros(new_mt.shape[0])\n  counter = 0\n  for i in is_unit_cols:\n    counter += 1\n    temp_vct =  new_mt[i] * counter\n    assert np.logical_not(np.logical_and(temp_vct > 0, aux_vct > 0).any()), 'For column {}, something went wrong when computing unit type1'.format(i)\n    aux_vct = aux_vct + temp_vct \n  new_mt['aux_col'] = aux_vct\n  monthly_price_type = new_mt.groupby(['id_date', 'aux_col'])['crent', 'price_per_sq_ft'].mean().reset_index()\n  monthly_price_type.columns = ['id_date', 'aux_col', 'avg_monthly_price_type', 'avg_price_per_sq_ft_type']\n  \n  new_mt = pd.merge(new_mt, monthly_price_type, on = ['id_date', 'aux_col'], how = 'left')\n  assert new_mt.shape[0] == mt.shape[0], 'The number of rows of the master table with the new ratio of the price and the monthly average price per type is wrong'\n  new_mt['ratio_price_avg_type'] = new_mt['crent'] /  new_mt['avg_monthly_price_type']\n  new_mt['ratio_price_sqft_avg_type'] = new_mt['price_per_sq_ft'] /  new_mt['avg_price_per_sq_ft_type']\n  new_mt.drop(columns = 'aux_col', inplace = True)\n  \n  \n  # replacing NAs\n  new_mt['ratio_price_avg'].fillna(1, inplace = True)\n  new_mt['ratio_price_sqft_avg'].fillna(1, inplace = True)\n  new_mt['ratio_price_avg_comm'].fillna(1, inplace = True)\n  new_mt['ratio_price_sqft_avg_comm'].fillna(1, inplace = True)\n  new_mt['ratio_price_avg_type'].fillna(1, inplace = True)\n  new_mt['ratio_price_sqft_avg_type'].fillna(1, inplace = True)  \n  \n  # additional synthetic variables\n  new_mt['ratio_price_mult'] = new_mt['ratio_price_avg'] * new_mt['ratio_price_avg_comm'] * new_mt['ratio_price_avg_type']\n  new_mt['ratio_price_sqft_mult'] = new_mt['ratio_price_sqft_avg'] * new_mt['ratio_price_sqft_avg_comm'] * new_mt['ratio_price_sqft_avg_type']\n  new_mt['ratio_price_avg_avg'] = (new_mt['ratio_price_avg'] + new_mt['ratio_price_avg_comm'] + new_mt['ratio_price_avg_type']) / 3\n  new_mt['ratio_price_sqft_avg_avg'] = (new_mt['ratio_price_sqft_avg'] + new_mt['ratio_price_sqft_avg_comm'] + new_mt['ratio_price_sqft_avg_type']) / 3\n  \n  return new_mt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97605211-73cb-49cc-a43b-09a370230422"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def add_sr_features(config, mt):\n  \n  \"\"\"Adds Service Requests features to master table. The number of rows is always unaltered. \n  \n  Parameters:\n  config: configuration dictionary, as defined in get_config.\n  mt: master table to which unit features are added\n\n  Returns:\n  Data frame with new columns related to Service Requests features. \n\n  \"\"\"  \n  \n  processed_sr = get_processed_srs(config)\n  new_mt = pd.merge(left = mt, right = processed_sr, left_on = ['htent', 'hunit', 'id_date'], right_on = ['htenant', 'hunit', 'id_date'], how = 'left')\n  assert new_mt.shape[0] == mt.shape[0], 'The number of rows of the master table with the SR features is not correct'\n  \n  sr_cols = [x for x in new_mt.columns if x.startswith('n_SR')]\n  for i in sr_cols:\n    new_mt[i].fillna(0, inplace = True)\n  \n  \n  return new_mt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e302d3ae-6d06-4b47-b123-1a9fb815c8f7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"add_features","dashboards":[],"notebookMetadata":null,"language":"python","widgets":{},"notebookOrigID":1624358662289445}},"nbformat":4,"nbformat_minor":0}
